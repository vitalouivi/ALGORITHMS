{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMcq9xUmad5IEz5F/i4qIpo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vitalouivi/ALGORITHMS/blob/main/%D0%9C%D0%BE%D0%B4%D1%83%D0%BB%D1%8C%D0%BD%D0%BE%D0%B52.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Задание 1\n",
        "#### По данным по Великобритании о потреблении цыплят ($Y$), среднедушевом доходе ($X1$), стоимости одного фунта цыплят ($X2$), стоимости одного фунта свинины ($X3$) и стоимости одного фунта говядины ($X4$)\n",
        "#### a) Необходимо построить, сравнить и проинтерпретировать уравнения регрессии вида:\n",
        "\n",
        "$1)  \\hat{y} = b_0 \\cdot x_2^{b_2}$  (Функция спроса)\\\n",
        "$2)  \\hat{y} = b_0 \\cdot x_1^{b_1}$  (Функция потребления)\\\n",
        "$3)  \\hat{y} = b_0 \\cdot x_1^{b_1} \\cdot x_2^{b_2}$  (Функция спроса-потребления)\\\n",
        "$4)  \\hat{y} = b_0 \\cdot x_2^{b_2} \\cdot x_3^{b_3} \\cdot x_4^{b_4}$  (Функция спроса с учетом цены на товары-заменители)\n",
        "\n",
        "#### b) Применить тест Шапиро-Уилка для проверки нормальности распределения $X1, X2, X3, X4$\n",
        "\n",
        "#### c) Для данных из пункта b, которые не прошли проверку, применить преобразования Бокса-Кокса.\n",
        "\n",
        "#### d) Применить критерий Манна-Уитни для оценки различий данных $X3$ и $X4$. Дать интерпретацию.\n",
        "\n",
        "#### e) Применить критерий Флигнера-Клипера для $X2$ и $X3$. Применить критерий Стьюдента для этих данных с учетом полученных результатов. Привести интерпретацию.\n",
        "\n",
        "\n",
        "#### Исходные данные для исследования приведены в табл. 1\n",
        "\n",
        "Таблица 1: Исходные данные\n",
        "```plaintext\n",
        "| t  | Y     | X1     | X2    | X3    | X4    |\n",
        "|----|-------|--------|-------|-------|-------|\n",
        "| 1  | 31.2  | 492.9  | 37.3  | 54.7  | 77.4  |\n",
        "| 2  | 33.3  | 528.6  | 38.1  | 63.7  | 80.2  |\n",
        "| 3  | 35.6  | 560.3  | 39.3  | 69.8  | 80.4  |\n",
        "| 4  | 36,4  | 624.6  | 37.8  | 65.9  | 83.9  |\n",
        "| 5  | 36.7  | 666.4  | 38.4  | 64.5  | 85.5  |\n",
        "| 6  | 38.4  | 717.8  | 40.1  | 70.0  | 93.7  |\n",
        "| 7  | 40.4  | 768.2  | 38.6  | 73.2  | 106.1 |\n",
        "| 8  | 40.3  | 843.3  | 39.8  | 67.8  | 104.8 |\n",
        "| 9  | 41.8  | 911.6  | 39.7  | 79.1  | 114.0 |\n",
        "| 10 | 40.4  | 931.1  | 52.1  | 95.4  | 124.1 |\n",
        "| 11 | 40.7  | 1021.5 | 48.9  | 94.2  | 127.6 |\n",
        "| 12 | 40.1  | 1165.9 | 58.3  | 123.5 | 142.9 |\n",
        "| 13 | 42.7  | 1349.6 | 57.9  | 129.9 | 143.6 |\n",
        "| 14 | 44.1  | 1449.4 | 56.5  | 117.6 | 139.2 |\n",
        "| 15 | 46.7  | 1575.5 | 63.7  | 130.9 | 165.5 |\n",
        "| 16 | 50.6  | 1759.1 | 61.6  | 129.8 | 203.3 |\n",
        "| 17 | 50.1  | 1994.2 | 58.9  | 128.0 | 219.6 |\n",
        "| 18 | 51.7  | 2258.1 | 66.4  | 141.0 | 221.6 |\n",
        "| 19 | 52.9  | 2478.7 | 70.4  | 168.2 | 232.6 |\n",
        "```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xti3HT634_mu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from matplotlib.lines import Line2D\n",
        "from scipy.stats import shapiro, boxcox, mannwhitneyu, fligner, ttest_ind\n"
      ],
      "metadata": {
        "id": "vrfkOpMRAPp0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#для начала перенесем данные из таблицы 1 в датафрейм\n",
        "# Исходные данные\n",
        "data = {\n",
        "    't': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19],\n",
        "    'Y': [31.2, 33.3, 35.6, 36.4, 36.7, 38.4, 40.4, 40.3, 41.8, 40.4, 40.7, 40.1, 42.7, 44.1, 46.7, 50.6, 50.1, 51.7, 52.9],\n",
        "    'X1': [492.9, 528.6, 560.3, 624.6, 666.4, 717.8, 768.2, 843.3, 911.6, 931.1, 1021.5, 1165.9, 1349.6, 1449.4, 1575.5, 1759.1, 1994.2, 2258.1, 2478.7],\n",
        "    'X2': [37.3, 38.1, 39.3, 37.8, 38.4, 40.1, 38.6, 39.8, 39.7, 52.1, 48.9, 58.3, 57.9, 56.5, 63.7, 61.6, 58.9, 66.4, 70.4],\n",
        "    'X3': [54.7, 63.7, 69.8, 65.9, 64.5, 70, 73.2, 67.8, 79.1, 95.4, 94.2, 123.5, 129.9, 117.6, 130.9, 129.8, 128, 141, 168.2],\n",
        "    'X4': [77.4, 80.2, 80.4, 83.9, 85.5, 93.7, 106.1, 104.8, 114, 124.1, 127.6, 142.9, 143.6, 139.2, 165.5, 203.3, 219.6, 221.6, 232.6]\n",
        "}\n",
        "\n",
        "# Создание DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Логарифмирование зависимой и независимых переменных\n",
        "df['log_Y'] = np.log(df['Y'])\n",
        "df['log_X1'] = np.log(df['X1'])\n",
        "df['log_X2'] = np.log(df['X2'])\n",
        "df['log_X3'] = np.log(df['X3'])\n",
        "df['log_X4'] = np.log(df['X4'])\n",
        "\n",
        "# Вывод данных\n",
        "print(df)\n",
        "\n",
        "# Генерация значений для x1, x2, x3, x4\n",
        "x1_values = np.linspace(df['X1'].min(), df['X1'].max(), 100)\n",
        "x2_values = np.linspace(df['X2'].min(), df['X2'].max(), 100)\n",
        "x3_values = np.linspace(df['X3'].min(), df['X3'].max(), 100)\n",
        "x4_values = np.linspace(df['X4'].min(), df['X4'].max(), 100)"
      ],
      "metadata": {
        "id": "mhQ2ByaW_n1h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uxTJuhbS47Fc"
      },
      "outputs": [],
      "source": [
        "#a1)\n",
        "# Оценка модели\n",
        "X = sm.add_constant(df['log_X2'])\n",
        "Y = df['log_Y']\n",
        "model = sm.OLS(Y, X).fit()\n",
        "\n",
        "# Получение и вывод оцененных коэффициентов\n",
        "b0_hat = np.exp(model.params['const'])\n",
        "b2_hat = model.params['log_X2']\n",
        "\n",
        "print(\"Оценка b0:\", b0_hat)\n",
        "print(\"Оценка b2:\", b2_hat)\n",
        "\n",
        "# Функция спроса\n",
        "demand_function = b0_hat * x2_values**b2_hat\n",
        "\n",
        "print(f\"Уравнение функции спроса на цыплят: Y = {b0_hat:.2f} * X2^{b2_hat:.2f}\")\n",
        "\n",
        "# Построение графика\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(df['X2'], df['Y'], label='Данные')\n",
        "plt.plot(x2_values, demand_function, label='Функция спроса', color='red')\n",
        "plt.title('Функция спроса на цыплят')\n",
        "plt.xlabel('Стоимость цыплят (X2)')\n",
        "plt.ylabel('Потребление цыплят (Y)')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Интерпретация уравнения функции спроса на цыплят\n",
        "\n",
        "Уравнение функции спроса на цыплят имеет вид:\n",
        "\n",
        "$Y = 4.84 \\cdot X_2^{0.55} $\n",
        "\n",
        "где:\n",
        "- $ Y $ представляет потребление цыплят.\n",
        "- $X_2 $ представляет цену на цыплят.\n",
        "\n",
        "#### Коэффициенты уравнения:\n",
        "\n",
        "1. **Коэффициент $b_0$:**\n",
        "   - Значение: 4.84.\n",
        "   - **Интерпретация:** Это условное количество потребления цыплят, когда цена $X_2$ равна нулю. Представляет базовый уровень спроса.\n",
        "\n",
        "2. **Коэффициент $b_2$:**\n",
        "   - Значение: 0.55.\n",
        "   - **Интерпретация:** Это степень, в которую возводится цена на цыплят. Увеличение цены влияет на потребление, и данная степень определяет характер этого воздействия. При сильном увеличении цены на цыплят можно ожидать, что потребление будет расти, но с убывающей скоростью. Это объясняется степенной зависимостью от цены.\n",
        "\n",
        "#### Вывод:\n",
        "\n",
        "Уравнение указывает на нелинейную зависимость между ценой на цыплят и потреблением. Увеличение цены влияет на потребление в соответствии с указанной степенью. Построенный график демонстрирует, как изменяется потребление при изменении цены на цыплят.\n"
      ],
      "metadata": {
        "id": "mB7dIQCUaaue"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#a2)\n",
        "# Оценка модели\n",
        "X = sm.add_constant(df['log_X1'])\n",
        "Y = df['log_Y']\n",
        "model = sm.OLS(Y, X).fit()\n",
        "\n",
        "# Получение и вывод оцененных коэффициентов\n",
        "b0_hat = np.exp(model.params['const'])\n",
        "b1_hat = model.params['log_X1']\n",
        "\n",
        "print(\"Оценка b0:\", b0_hat)\n",
        "print(\"Оценка b1:\", b1_hat)\n",
        "\n",
        "# Функция потребления\n",
        "consumption_function = b0_hat * x1_values**b1_hat\n",
        "print(f\"Уравнение функции потребления цыплят: Y = {b0_hat:.2f} * X1^{b1_hat:.2f}\")\n",
        "\n",
        "# Построение графика\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(df['X1'], df['Y'], label='Данные')\n",
        "plt.plot(x1_values, demand_function, label='Функция потребления цыплят', color='red')\n",
        "plt.title('Функция потребления цыплят')\n",
        "plt.xlabel('Среднедушевой доход (X1)')\n",
        "plt.ylabel('Потребление цыплят (Y)')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2rErHPqgJy-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Интерпретация уравнения функции потребления цыплят\n",
        "\n",
        "Уравнение функции потребления цыплят имеет вид:\n",
        "\n",
        "$Y = 5.73 \\cdot X_1^{0.28} $\n",
        "\n",
        "где:\n",
        "- $ Y $ представляет объем потребления цыплят.\n",
        "- $ X_1 $ представляет среднедушевой доход.\n",
        "\n",
        "#### Коэффициенты уравнения:\n",
        "\n",
        "1. **Коэффициент $b_0$:**\n",
        "   - Значение: 5.73.\n",
        "   - **Интерпретация:** Это начальный объем потребления цыплят при среднедушевом доходе $(X_1)$, равном нулю или в базовых условиях.\n",
        "\n",
        "2. **Коэффициент $b_1$:**\n",
        "   - Значение: 0.28.\n",
        "   - **Интерпретация:** Это степень, в которую возводится среднедушевой доход $(X_1)$. Увеличение дохода будет влиять на объем потребления, и данная степень определяет характер этого воздействия.так как данный коэффициент меньше 1, это указывает на убывающую скорость увеличения потребления при росте дохода.\n",
        "\n",
        "#### Вывод:\n",
        "\n",
        "Уравнение указывает на нелинейную зависимость между среднедушевым доходом и объемом потребления цыплят. Увеличение дохода влияет на объем потребления с убывающей скоростью, определенной степенью $b_1$. Построение графика этой функции позволит визуально представить, как изменяется объем потребления цыплят относительно среднедушевого дохода.\n"
      ],
      "metadata": {
        "id": "lxI05FXKcsoy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#a3)\n",
        "# Оценка модели\n",
        "X = sm.add_constant(df[['log_X1', 'log_X2']])\n",
        "Y = df['log_Y']\n",
        "model = sm.OLS(Y, X).fit()\n",
        "\n",
        "# Получение и вывод оцененных коэффициентов\n",
        "b0_hat = np.exp(model.params['const'])\n",
        "b1_hat = model.params['log_X1']\n",
        "b2_hat = model.params['log_X2']\n",
        "\n",
        "print(\"Оценка b0:\", b0_hat)\n",
        "print(\"Оценка b1:\", b1_hat)\n",
        "print(\"Оценка b2:\", b2_hat)\n",
        "\n",
        "# Создание сетки для всех комбинаций x1 и x2\n",
        "x1_mesh, x2_mesh = np.meshgrid(x1_values, x2_values)\n",
        "\n",
        "# Функция спроса-потребления\n",
        "demand_consumption_function = b0_hat * x1_mesh**b1_hat * x2_mesh**b2_hat\n",
        "\n",
        "print(f\"Уравнение функции спроса-потребления цыплят: Y = {b0_hat:.2f} * X1^{b1_hat:.2f}* X2^{b2_hat:.2f}\")\n",
        "\n",
        "# Построение 3D-графика\n",
        "fig = plt.figure(figsize=(10, 8))\n",
        "ax = fig.add_subplot(projection='3d')\n",
        "scatter = ax.scatter(df['X1'], df['X2'], df['Y'], label='Данные', color='blue')\n",
        "surf = ax.plot_trisurf(df['X1'], df['X2'], df['Y'], cmap='viridis', alpha=0.5, label='Функция спроса-потребления')\n",
        "\n",
        "# Добавление цветовой шкалы\n",
        "fig.colorbar(surf, ax=ax, label='Y')\n",
        "\n",
        "# Добавление легенды\n",
        "custom_legend = [Line2D([0], [0], marker='o', color='w', label='Данные', markerfacecolor='blue', markersize=10),\n",
        "                 Line2D([0], [0], linestyle='-', color='w', label='Функция спроса-потребления', markerfacecolor='black')]\n",
        "\n",
        "ax.legend(handles=custom_legend)\n",
        "\n",
        "ax.set_xlabel('X1')\n",
        "ax.set_ylabel('X2')\n",
        "ax.set_zlabel('Y')\n",
        "ax.set_title('Функция спроса-потребления цыплят')\n",
        "plt.show()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vqlpy-IpJyzs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#a4)\n",
        "# Оценка модели\n",
        "X = sm.add_constant(df[['log_X2', 'log_X3', 'log_X4' ]])\n",
        "Y = df['log_Y']\n",
        "model = sm.OLS(Y, X).fit()\n",
        "\n",
        "# Получение и вывод оцененных коэффициентов\n",
        "b0_hat = np.exp(model.params['const'])\n",
        "b2_hat = model.params['log_X2']\n",
        "b3_hat = model.params['log_X3']\n",
        "b4_hat = model.params['log_X4']\n",
        "\n",
        "print(\"Оценка b0:\", b0_hat)\n",
        "print(\"Оценка b2:\", b2_hat)\n",
        "print(\"Оценка b3:\", b3_hat)\n",
        "print(\"Оценка b4:\", b4_hat)\n",
        "\n",
        "# Создание сетки для всех комбинаций x2, x3 и x4\n",
        "x2_mesh, x3_mesh, x4_mesh = np.meshgrid(x2_values, x3_values, x4_values)\n",
        "\n",
        "# Функция спроса с учетом цены на товары-заменители\n",
        "demand_function_substitutes = b0_hat * x2_mesh**b2_hat * x3_mesh**b3_hat * x4_mesh**b4_hat\n",
        "\n",
        "print(f\"Уравнение функции спроса с учетом цены на товары-заменители: Y = {b0_hat:.2f} * X2^{b2_hat:.2f} * X3^{b3_hat:.2f} * X4^{b4_hat:.2f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "A0DaN-HZJybk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#b)\n",
        "\n",
        "# Проведение теста Шапиро-Уилка\n",
        "statistic_X1, p_value_X1 = shapiro(df['X1'])\n",
        "statistic_X2, p_value_X2 = shapiro(df['X2'])\n",
        "statistic_X3, p_value_X3 = shapiro(df['X3'])\n",
        "statistic_X4, p_value_X4 = shapiro(df['X4'])\n",
        "\n",
        "# Вывод результатов теста\n",
        "print(\"Тест Шапиро-Уилка для X1: statistic =\", statistic_X1, \", p-value =\", p_value_X1)\n",
        "print(\"Тест Шапиро-Уилка для X2: statistic =\", statistic_X2, \", p-value =\", p_value_X2)\n",
        "print(\"Тест Шапиро-Уилка для X3: statistic =\", statistic_X3, \", p-value =\", p_value_X3)\n",
        "print(\"Тест Шапиро-Уилка для X4: statistic =\", statistic_X4, \", p-value =\", p_value_X4)\n"
      ],
      "metadata": {
        "id": "CWgxvT2x7uRq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Примем общепринятый уровень значимости для этого типа тестов - 0.05, сравним результаты теста Шапиро-Уилка с выбранным уровнем значимости и заметим, что все четыре теста показывают низкие p-value, что может свидетельствовать о том, что данные не имеют нормальное распределение. Однако, стоит помнить, что результаты тестов могут быть чувствительны к размеру выборки, а в нашем случае выборка очень мала. Сославшись на это, для Х1 и Х3 можно было бы не проводить применить преобразования Бокса-Кокса, но мы проведем."
      ],
      "metadata": {
        "id": "T3ppccLw9ddy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#с)\n",
        "# Применение преобразования Бокса-Кокса для данных, которые не прошли тест Шапиро-Уилка\n",
        "data_X1_transformed, lambda_X1 = boxcox(df['X1'])\n",
        "data_X2_transformed, lambda_X2 = boxcox(df['X2'])\n",
        "data_X3_transformed, lambda_X3 = boxcox(df['X3'])\n",
        "data_X4_transformed, lambda_X4 = boxcox(df['X4'])\n",
        "\n",
        "# Вывод оптимальных значений параметра λ:\n",
        "print(\"Оптимальное значение λ для X1:\", lambda_X1)\n",
        "print(\"Оптимальное значение λ для X2:\", lambda_X2)\n",
        "print(\"Оптимальное значение λ для X3:\", lambda_X3)\n",
        "print(\"Оптимальное значение λ для X4:\", lambda_X4)\n",
        "\n",
        "\n",
        "# Теперь можем использовать преобразованные данные для анализа\n",
        "# Например, применим тест Шапиро-Уилка к преобразованным данным\n",
        "statistic_transformed_X1, p_value_transformed_X1 = shapiro(data_X1_transformed)\n",
        "statistic_transformed_X2, p_value_transformed_X2 = shapiro(data_X2_transformed)\n",
        "statistic_transformed_X3, p_value_transformed_X3 = shapiro(data_X3_transformed)\n",
        "statistic_transformed_X4, p_value_transformed_X4 = shapiro(data_X4_transformed)\n",
        "\n",
        "# Вывод результатов теста на нормальность для преобразованных данных\n",
        "print(\"Тест Шапиро-Уилка для преобразованных данных X1: statistic =\", statistic_transformed_X1, \", p-value =\", p_value_transformed_X1)\n",
        "print(\"Тест Шапиро-Уилка для преобразованных данных X2: statistic =\", statistic_transformed_X2, \", p-value =\", p_value_transformed_X2)\n",
        "print(\"Тест Шапиро-Уилка для преобразованных данных X3: statistic =\", statistic_transformed_X3, \", p-value =\", p_value_transformed_X3)\n",
        "print(\"Тест Шапиро-Уилка для преобразованных данных X4: statistic =\", statistic_transformed_X4, \", p-value =\", p_value_transformed_X4)"
      ],
      "metadata": {
        "id": "QTNBPLt5-UFU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для преобразованных данных X2  p-value все еще меньше 0.05, что может свидетельствовать о том, что данные не полностью соответствуют нормальному распределению."
      ],
      "metadata": {
        "id": "vJfCcb3D_uQq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#d)\n",
        "# Проведение критерия Манна-Уитни\n",
        "statistic, p_value = mannwhitneyu(df['X3'], df['X4'])\n",
        "\n",
        "# Вывод результатов теста\n",
        "print(\"Статистика U =\", statistic)\n",
        "print(\"p-value =\", p_value)"
      ],
      "metadata": {
        "id": "_iojJwdgAA6_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Уровень значимости p-value равен 0.0228, что меньше часто используемого порогового значения 0.05. Таким образом, на уровне значимости 0.05 мы отвергаем нулевую гипотезу о том, что нет статистически значимых различий между X3 и X4.\n",
        "\n",
        "Интерпретация: Есть статистически значимые различия между X3 и X4. Таким образом, на основе теста Манна-Уитни у нас есть достаточные доказательства для утверждения, что распределения X3 и X4 различны."
      ],
      "metadata": {
        "id": "rwbeDK3AAwCx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#e)\n",
        "# Проведение критерия Флигнера-Клипера\n",
        "statistic_fligner, p_value_fligner = fligner(df['X2'], df['X3'])\n",
        "\n",
        "# Проведение критерия Стьюдента с учетом результатов Флигнера-Клипера\n",
        "# Если p-value Флигнера-Клипера < 0.05 (уровень значимости), используем параметр equal_var=False\n",
        "# Иначе, используем параметр equal_var=True\n",
        "if p_value_fligner < 0.05:\n",
        "    equal_var = False\n",
        "else:\n",
        "    equal_var = True\n",
        "\n",
        "# Проведение критерия Стьюдента\n",
        "statistic_t, p_value_t = ttest_ind(df['X2'], df['X3'], equal_var=equal_var)\n",
        "\n",
        "# Вывод результатов тестов\n",
        "print(\"Критерий Флигнера-Клипера:\")\n",
        "print(\"Статистика =\", statistic_fligner)\n",
        "print(\"p-value =\", p_value_fligner)\n",
        "print(\"\\nКритерий Стьюдента:\")\n",
        "print(\"Статистика t =\", statistic_t)\n",
        "print(\"p-value =\", p_value_t)"
      ],
      "metadata": {
        "id": "TsNMyOZKF2cC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Критерий Флигнера-Клипера:**\n",
        "- Статистика = 16.7975\n",
        "- p-value = 4.1589e-05 (очень маленькое число)\n",
        "\n",
        "**Критерий Стьюдента:**\n",
        "- Статистика t = -5.9376\n",
        "- p-value = 5.4746e-06 (очень маленькое число)\n",
        "\n",
        "**Интерпретация:**\n",
        "\n",
        "1. **Критерий Флигнера-Клипера:**\n",
        "   - Так как p-value крайне маленькое (меньше выбранного уровня значимости 0.05), мы отвергаем нулевую гипотезу о равенстве дисперсий. Таким образом, дисперсии между X2 и X3 статистически различны.\n",
        "\n",
        "2. **Критерий Стьюдента:**\n",
        "   - Так как p-value также крайне маленькое (меньше 0.05), мы отвергаем нулевую гипотезу о равенстве средних значений. Это указывает на статистически значимые различия между X2 и X3.\n",
        "\n",
        "Итак, на основе обоих тестов есть статистически значимые различия между X2 и X3, учитывая различие в дисперсиях, как указано Критерием Флигнера-Клипера. Учитывая результаты Критерия Стьюдента, отрицательное значение t-статистики также указывает на то, что среднее значение X2 меньше, чем среднее значение X3.\n"
      ],
      "metadata": {
        "id": "829v3qr0HkFS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Задание 2\n",
        "#### По данным из файла «задание2.xlsx» показателей деятельности 50 фирм, оказывающих фото- и видео-услуги в городе N, за 2019 г. рассмотреть возможности оценивания нелинейной, в частности полиномиальной, регрессии прибыльности вложений в оборудование (profitability, %) на показатели среднего числа сотрудников на один проект (staff), среднемесячного числа проектов (projects), доли расходов на рекламу и продвижение своего бренда (adverts, %).\n",
        "#### а) Найти степень полинома, при которой коэффициент детерминации оказывается близким к 1.\n",
        "\n",
        "\n",
        "#### b) Показать, что результат достигнут за счет переобучения модели.\n",
        "\n",
        "\n",
        "\n",
        "#### с) Выбрать оптимальную степень полинома, в том числе с содержательной точки зрения, предполагая, что фирмы можно считать однородными по прочим возможным показателям их деятельности.\n"
      ],
      "metadata": {
        "id": "ogABMAsdInjA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Загрузка данных из файла Excel\n",
        "data = pd.read_excel(\"задание2.xlsx\")\n",
        "\n",
        "# Подготовка данных\n",
        "X = data[['staff', 'projects', 'adverts']]\n",
        "y = data['profitability']\n",
        "\n",
        "# Разделение данных на обучающую и тестовую выборки\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Функция для обучения полиномиальной регрессии, оценки R^2 и предсказания\n",
        "def train_and_evaluate_polynomial_regression(degree, X_train, X_test, y_train, y_test):\n",
        "    # Преобразование признаков в полиномиальные\n",
        "    poly = PolynomialFeatures(degree=degree)\n",
        "    X_train_poly = poly.fit_transform(X_train)\n",
        "    X_test_poly = poly.transform(X_test)\n",
        "\n",
        "    # Обучение линейной регрессии на полиномиальных признаках\n",
        "    model = LinearRegression()\n",
        "    model.fit(X_train_poly, y_train)\n",
        "\n",
        "    # Предсказание на тестовой и обучающей выборках\n",
        "    y_test_pred = model.predict(X_test_poly)\n",
        "    y_train_pred = model.predict(poly.transform(X_train))\n",
        "\n",
        "    # Оценка R^2\n",
        "    r2_test = r2_score(y_test, y_test_pred)\n",
        "    r2_train = r2_score(y_train, y_train_pred)\n",
        "\n",
        "    return r2_train, r2_test\n",
        "\n",
        "# a) Найти степень полинома, при которой коэффициент детерминации близок к 1\n",
        "best_degree_high_r2 = None\n",
        "best_r2_high = -np.inf\n",
        "\n",
        "for degree in range(1, 10):\n",
        "    r2_train, r2_test = train_and_evaluate_polynomial_regression(degree, X_train, X_test, y_train, y_test)\n",
        "    if r2_test > best_r2_high:\n",
        "        best_r2_high = r2_test\n",
        "        best_degree_high_r2 = degree\n",
        "\n",
        "# Вывести результаты\n",
        "print(f\"a) Оптимальная степень полинома для высокого R^2: {best_degree_high_r2}\")\n",
        "print(f\"   Наилучший коэффициент детерминации (R^2) на тестовой выборке: {best_r2_high}\")\n",
        "\n",
        "# b) Показать, что результат достигнут за счет переобучения модели\n",
        "degrees = range(1, 10)\n",
        "r2_train_values = []\n",
        "r2_test_values = []\n",
        "\n",
        "for degree in degrees:\n",
        "    r2_train, r2_test = train_and_evaluate_polynomial_regression(degree, X_train, X_test, y_train, y_test)\n",
        "    r2_train_values.append(r2_train)\n",
        "    r2_test_values.append(r2_test)\n",
        "\n",
        "# Вывести результаты\n",
        "plt.plot(degrees, r2_train_values, marker='o', label='Обучающая выборка')\n",
        "plt.plot(degrees, r2_test_values, marker='o', label='Тестовая выборка')\n",
        "plt.title('Зависимость R^2 от степени полинома')\n",
        "plt.xlabel('Степень полинома')\n",
        "plt.ylabel('R^2')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# c) Выбрать оптимальную степень полинома с содержательной точки зрения\n",
        "# В данном случае, просто будем считать, что лучшая степень та, при которой R^2 максимальный\n",
        "best_degree_optimal = None\n",
        "best_r2_optimal = -np.inf\n",
        "\n",
        "for degree in range(1, 10):\n",
        "    r2_train, r2_test = train_and_evaluate_polynomial_regression(degree, X_train, X_test, y_train, y_test)\n",
        "    if r2_test > best_r2_optimal:\n",
        "        best_r2_optimal = r2_test\n",
        "        best_degree_optimal = degree\n",
        "\n",
        "# Вывести результаты\n",
        "print(f\"c) Оптимальная степень полинома с содержательной точки зрения: {best_degree_optimal}\")\n",
        "print(f\"   Наилучший коэффициент детерминации (R^2) на тестовой выборке: {best_r2_optimal}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-Mv8G-yQKFrD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "R^2 на обучающей выборке значительно выше, чем на тестовой, это признак переобучения."
      ],
      "metadata": {
        "id": "Ds5m-H9rNEpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Задание 3\n",
        "#### Применить метод главных компонент для понижения размерности данных о результативности деятельности российских вузов. Данные в файле «задание3.xlsx»\n",
        "#### а) Определить минимальное количество компонент, которые необходимо использовать для сохранения 75% первоначальной информации.\n",
        "\n",
        "#### b) Выписать формулы зависимости главных компонент из пункта а) от первоначальных данных."
      ],
      "metadata": {
        "id": "wS1sexVXbw7S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Загрузка данных из файла Excel\n",
        "data = pd.read_excel(\"задание3.xlsx\")\n",
        "\n",
        "# Вывод первых нескольких строк данных для ознакомления\n",
        "print(data.head())\n",
        "\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Выделение признаков и масштабирование данных\n",
        "#X = data.drop('ВУЗ', axis=1)  # Предполагая, что 'ВУЗ' - это название вуза и не является признаком\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Применение PCA\n",
        "pca = PCA()\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "# Вычисление объясненной дисперсии для каждой компоненты\n",
        "explained_variance_ratio = pca.explained_variance_ratio_\n",
        "\n",
        "# Вывод объясненной дисперсии для каждой компоненты\n",
        "print(\"Объясненная дисперсия для каждой компоненты:\")\n",
        "print(explained_variance_ratio)\n",
        "\n",
        "# Вычисление кумулятивной суммы объясненной дисперсии\n",
        "cumulative_variance_ratio = np.cumsum(explained_variance_ratio)\n",
        "\n",
        "# Находим индекс, на котором кумулятивная дисперсия превышает 75%\n",
        "min_components = np.argmax(cumulative_variance_ratio >= 0.75) + 1\n",
        "\n",
        "# Вывод минимального количества компонент\n",
        "print(f\"Минимальное количество компонент для сохранения 75% первоначальной информации: {min_components}\")\n",
        "\n",
        "# Получение матрицы главных компонент\n",
        "principal_components = pca.components_\n",
        "\n",
        "# Вывод формул зависимости главных компонент от исходных данных\n",
        "for i in range(min_components):\n",
        "    formula = \" + \".join([f\"{round(weight, 3)} * {feature}\" for weight, feature in zip(principal_components[i], X.columns)])\n",
        "    print(f\"Главная компонента {i+1}: PC{i+1} = {formula}\")\n"
      ],
      "metadata": {
        "id": "txEjYyMacOfv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Задание 4\n",
        "#### По данным из файла «задание4.xls» обучить модель логистической регрессии с целью прогнозирования увольнения сотрудника.\n",
        "#### а) Отобрать переменные, которые будут включаться в модель. Обосновать сделанный выбор. Обучить модель логистической регрессии. Дать интерпретацию полученных результатов.\n",
        "\n",
        "#### b) Привести матрицу ошибок, рассмотреть различные метрики качества модели.\n",
        "\n",
        "#### b) c) Построить ROC-кривую.\n",
        "\n",
        "Описание переменных:\n",
        "target – сотрудник уволится в следующем году (0-нет, 1-да)\\\n",
        "age-возраст\\\n",
        "educ- образование (1-начальное, 2-среднее, 3 -неоконченное высшее, 4-два и более высших образования, 5-кандидат наук, 6-доктор наук)\\\n",
        "work_exp – стаж работы (лет)\\\n",
        "interest – оценка сотрудником интереса к работе (от 0 до 10)\\\n",
        "coffee- среднее количество чашек кофе, выпиваемых сотрудником за рабочий день\\\n",
        "boss_educ -образование руководителя (1-начальное, 2-среднее, 3 -неоконченное высшее, 4-два и более высших образования, 5-кандидат наук, 6-доктор наук)\\\n",
        "passport- наличие загранпаспорта у сотрудника (1-есть, 0 -нет)\\\n",
        "green -степень озеленения офиса (от 1 до 5)\\\n",
        "floor – этаж работы\\\n",
        "children – количество детей у сотрудника\\\n",
        "climate- удовлетворенность рабочей атмосферой (от 0 до 4)\\\n",
        "offhour – наличие переработок (1-да, 0 -нет)\\\n",
        "dist – расстояние до работы\\\n",
        "salary – удовлетворенность заработной платой (1-да, 0 -нет)\\\n",
        "height- рост сотрудника\\\n",
        "lunch- средняя цена бизнес-ланча в офисе\n"
      ],
      "metadata": {
        "id": "_LgZ33L1Wu6D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Импортируем необходимые библиотеки\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, roc_auc_score, auc\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Загрузим данные из файла\n",
        "data = pd.read_excel(\"задание4.xls\")\n",
        "\n",
        "# Посмотрим на первые несколько строк данных, чтобы понять структуру\n",
        "print(data.head())\n",
        "\n",
        "# Рассчитаем и отобразим первую матрицу корреляции для удаления некоторых из признаков которые показывают сильную корреляцию\n",
        "corr_matrix = data.corr()\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(corr_matrix, annot=True, cmap=\"coolwarm\")\n",
        "plt.title(\"Матрица корреляции (до удаления 'educ')\")\n",
        "plt.show()\n",
        "\n",
        "# Удалим коррелирующий признак 'educ' и 'floor'\n",
        "data = data.drop(columns=['educ', 'work_exp'])\n",
        "\n",
        "# Рассчитаем и отобразим вторую матрицу корреляции\n",
        "corr_matrix = data.corr()\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(corr_matrix, annot=True, cmap=\"coolwarm\")\n",
        "plt.title(\"Матрица корреляции (после удаления 'educ')\")\n",
        "plt.show()\n",
        "# Отбираем переменные для модели\n",
        "# В данном примере выберем все переменные, кроме 'target' (целевая переменная)\n",
        "X = data.drop(columns=['target'])\n",
        "y = data['target']\n",
        "\n",
        "# Разделяем данные на обучающую и тестовую выборки\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Обучаем модель логистической регрессии\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Делаем предсказания на тестовой выборке\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Оцениваем качество модели\n",
        "# Матрица ошибок\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "print(\"Матрица ошибок:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "# Классификационный отчет\n",
        "class_report = classification_report(y_test, y_pred)\n",
        "print(\"\\nКлассификационный отчет:\")\n",
        "print(class_report)\n",
        "\n",
        "# ROC-кривая и площадь под ней\n",
        "y_probs = model.predict_proba(X_test)[:, 1]\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_probs)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "# Построение ROC-кривой\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = {:.2f})'.format(roc_auc))\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IXkKlHILXiGD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}